{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Acquire-Store-df-Using-Acquire-Function\" data-toc-modified-id=\"Acquire-Store-df-Using-Acquire-Function-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Acquire Store df Using Acquire Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#1-3-Exercises-with-Store-df\" data-toc-modified-id=\"1-3-Exercises-with-Store-df-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>1-3 Exercises with Store df</a></span></li><li><span><a href=\"#4.-Date-Parts\" data-toc-modified-id=\"4.-Date-Parts-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>4. Date Parts</a></span></li><li><span><a href=\"#5.-Create-New-Calculated-Column-Using-.assign()\" data-toc-modified-id=\"5.-Create-New-Calculated-Column-Using-.assign()-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>5. Create New Calculated Column Using .assign()</a></span></li><li><span><a href=\"#6.-Using-.diff()\" data-toc-modified-id=\"6.-Using-.diff()-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>6. Using .diff()</a></span></li><li><span><a href=\"#7.-Build-Functions\" data-toc-modified-id=\"7.-Build-Functions-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>7. Build Functions</a></span></li></ul></li><li><span><a href=\"#Acuire-OPS-German-Energy-df\" data-toc-modified-id=\"Acuire-OPS-German-Energy-df-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Acuire OPS German Energy df</a></span><ul class=\"toc-item\"><li><span><a href=\"#1-4-Prepare-German-Energy-df\" data-toc-modified-id=\"1-4-Prepare-German-Energy-df-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>1-4 Prepare German Energy df</a></span></li><li><span><a href=\"#5.-Build-Function\" data-toc-modified-id=\"5.-Build-Function-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>5. Build Function</a></span></li></ul></li><li><span><a href=\"#Acquire-San-Francisco-Temps-DataFrame\" data-toc-modified-id=\"Acquire-San-Francisco-Temps-DataFrame-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Acquire San Francisco Temps DataFrame</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Resample-by-the-day-and-take-the-average-temperature.-Visualize-the-average-temperature-over-time.\" data-toc-modified-id=\"1.-Resample-by-the-day-and-take-the-average-temperature.-Visualize-the-average-temperature-over-time.-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>1. Resample by the day and take the average temperature. Visualize the average temperature over time.</a></span></li><li><span><a href=\"#2.-Write-the-code-necessary-to-visualize-the-minimum-temperature-over-time.\" data-toc-modified-id=\"2.-Write-the-code-necessary-to-visualize-the-minimum-temperature-over-time.-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>2. Write the code necessary to visualize the minimum temperature over time.</a></span></li><li><span><a href=\"#3.-Write-the-code-necessary-to-visualize-the-maximum-temperature-over-time.\" data-toc-modified-id=\"3.-Write-the-code-necessary-to-visualize-the-maximum-temperature-over-time.-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>3. Write the code necessary to visualize the maximum temperature over time.</a></span></li><li><span><a href=\"#4.-Which-month-is-the-coldest,-on-average?\" data-toc-modified-id=\"4.-Which-month-is-the-coldest,-on-average?-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>4. Which month is the coldest, on average?</a></span></li><li><span><a href=\"#5.-Which-month-has-the-highest-average-temperature?\" data-toc-modified-id=\"5.-Which-month-has-the-highest-average-temperature?-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>5. Which month has the highest average temperature?</a></span></li><li><span><a href=\"#6.-Resample-by-the-day-and-calculate-the-min-and-max-temp-for-the-day.-Use-this-resampled-dataframe-to-calculate-the-change-in-temperature-for-the-day.-Which-month-has-the-highest-daily-temperature-variability?\" data-toc-modified-id=\"6.-Resample-by-the-day-and-calculate-the-min-and-max-temp-for-the-day.-Use-this-resampled-dataframe-to-calculate-the-change-in-temperature-for-the-day.-Which-month-has-the-highest-daily-temperature-variability?-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>6. Resample by the day and calculate the min and max temp for the day. Use this resampled dataframe to calculate the change in temperature for the day. Which month has the highest daily temperature variability?</a></span></li><li><span><a href=\"#7.-Bonus:-Visualize-the-daily-min,-average,-and-max-temperature-over-time-on-a-single-line-plot.\" data-toc-modified-id=\"7.-Bonus:-Visualize-the-daily-min,-average,-and-max-temperature-over-time-on-a-single-line-plot.-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>7. Bonus: Visualize the daily min, average, and max temperature over time on a single line plot.</a></span></li></ul></li><li><span><a href=\"#Acquire-flights\" data-toc-modified-id=\"Acquire-flights-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Acquire flights</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convert-df-to-DateTime-Index\" data-toc-modified-id=\"Convert-df-to-DateTime-Index-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Convert df to DateTime Index</a></span></li><li><span><a href=\"#1.-Convert-any-negative-delays-to-0.\" data-toc-modified-id=\"1.-Convert-any-negative-delays-to-0.-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>1. Convert any negative delays to 0.</a></span></li><li><span><a href=\"#2.-Which-hour-of-the-day-has-the-highest-average-delay?\" data-toc-modified-id=\"2.-Which-hour-of-the-day-has-the-highest-average-delay?-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>2. Which hour of the day has the highest average delay?</a></span></li><li><span><a href=\"#3.-Does-the-day-of-the-week-make-a-difference-in-the-delay-amount?\" data-toc-modified-id=\"3.-Does-the-day-of-the-week-make-a-difference-in-the-delay-amount?-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>3. Does the day of the week make a difference in the delay amount?</a></span></li><li><span><a href=\"#4.-Does-the-month-make-a-difference-in-the-delay-amount?\" data-toc-modified-id=\"4.-Does-the-month-make-a-difference-in-the-delay-amount?-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>4. Does the month make a difference in the delay amount?</a></span></li><li><span><a href=\"#Just-Curious-Stuff...\" data-toc-modified-id=\"Just-Curious-Stuff...-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Just Curious Stuff...</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('figure', figsize=(11, 9))\n",
    "plt.rc('font', size=13)\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from datetime import timedelta, datetime as dt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from ts_acquire import get_store_data, get_store_data_dti, opsd_germany_daily, opsd_germany_daily_dti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire Store df Using Acquire Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_id</th>\n",
       "      <th>store_address</th>\n",
       "      <th>store_city</th>\n",
       "      <th>store_id</th>\n",
       "      <th>store_state</th>\n",
       "      <th>store_zipcode</th>\n",
       "      <th>item_brand</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_upc12</th>\n",
       "      <th>item_upc14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Tue, 01 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>1</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>78253</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>1</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Wed, 02 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>2</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>78253</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>1</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Thu, 03 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>3</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>78253</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>1</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Fri, 04 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>4</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>78253</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>1</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Sat, 05 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>5</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>78253</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>1</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sale_amount                      sale_date  sale_id  \\\n",
       "0         13.0  Tue, 01 Jan 2013 00:00:00 GMT        1   \n",
       "1         11.0  Wed, 02 Jan 2013 00:00:00 GMT        2   \n",
       "2         14.0  Thu, 03 Jan 2013 00:00:00 GMT        3   \n",
       "3         13.0  Fri, 04 Jan 2013 00:00:00 GMT        4   \n",
       "4         10.0  Sat, 05 Jan 2013 00:00:00 GMT        5   \n",
       "\n",
       "            store_address   store_city  store_id store_state  store_zipcode  \\\n",
       "0  12125 Alamo Ranch Pkwy  San Antonio         1          TX          78253   \n",
       "1  12125 Alamo Ranch Pkwy  San Antonio         1          TX          78253   \n",
       "2  12125 Alamo Ranch Pkwy  San Antonio         1          TX          78253   \n",
       "3  12125 Alamo Ranch Pkwy  San Antonio         1          TX          78253   \n",
       "4  12125 Alamo Ranch Pkwy  San Antonio         1          TX          78253   \n",
       "\n",
       "  item_brand  item_id                       item_name  item_price  \\\n",
       "0   Riceland        1  Riceland American Jazmine Rice        0.84   \n",
       "1   Riceland        1  Riceland American Jazmine Rice        0.84   \n",
       "2   Riceland        1  Riceland American Jazmine Rice        0.84   \n",
       "3   Riceland        1  Riceland American Jazmine Rice        0.84   \n",
       "4   Riceland        1  Riceland American Jazmine Rice        0.84   \n",
       "\n",
       "    item_upc12   item_upc14  \n",
       "0  35200264013  35200264013  \n",
       "1  35200264013  35200264013  \n",
       "2  35200264013  35200264013  \n",
       "3  35200264013  35200264013  \n",
       "4  35200264013  35200264013  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df = get_store_data()\n",
    "big_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3 Exercises with Store df\n",
    "\n",
    "1. Convert date column to datetime format.\n",
    "2. Plot the distribution of `sale_amount` and `item_price`.\n",
    "3. Set the index to be the datetime variable. (I added the code below into an acquire function called `get_store_data_dti()`, so that I have csv files of store data I can read with or without a DateTimeIndex.)\n",
    "\n",
    "```python\n",
    "df['sale_date'] = pd.to_datetime(df.sale_date)\n",
    "\n",
    "df = df.set_index('sale_date').sort_index()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_data_dti():\n",
    "    \"\"\"\n",
    "    This function checks for csv files\n",
    "    for items, sales, stores, and big_df \n",
    "    if there are none, it creates them.\n",
    "    It returns one big_df of merged dfs\n",
    "    with sale_date as a DateTimeIndex.\n",
    "    \"\"\"\n",
    "    # check for csv files or create them\n",
    "    if os.path.isfile('items.csv'):\n",
    "        items_df = pd.read_csv('items.csv', index_col=0)\n",
    "    else:\n",
    "        items_df = get_df('items')\n",
    "        \n",
    "    if os.path.isfile('stores.csv'):\n",
    "        stores_df = pd.read_csv('stores.csv', index_col=0)\n",
    "    else:\n",
    "        stores_df = get_df('stores')\n",
    "        \n",
    "    if os.path.isfile('sales.csv'):\n",
    "        sales_df = pd.read_csv('sales.csv', index_col=0)\n",
    "    else:\n",
    "        sales_df = get_df('sales')\n",
    "        \n",
    "    if os.path.isfile('big_df_dti.csv'):\n",
    "        df = pd.read_csv('big_df_dti.csv')\n",
    "        return df\n",
    "    else:\n",
    "        # merge all of the DataFrames into one\n",
    "        df = pd.merge(sales_df, stores_df, left_on='store', right_on='store_id').drop(columns={'store'})\n",
    "        df = pd.merge(df, items_df, left_on='item', right_on='item_id').drop(columns={'item'})\n",
    "\n",
    "        # convert sale_date to DateTime Index\n",
    "        df['sale_date'] = pd.to_datetime(df.sale_date)\n",
    "        df = df.set_index('sale_date').sort_index()\n",
    "\n",
    "        # write merged DateTime df with all data to directory for future use\n",
    "        df.to_csv('big_df_dti.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.item_price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First day in df is Jan 1st, 2013\n",
    "\n",
    "df.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasst day in df is Dec 31, 2017\n",
    "\n",
    "df.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_plot(df, col, bins):\n",
    "    \"\"\"\n",
    "    function takes in a DataFrame, \n",
    "    a string for column name or list, and \n",
    "    integer for number of bins and\n",
    "    displays a histogram of the column\n",
    "    \"\"\"\n",
    "    plt.hist(df[col], bins=bins, color='thistle')\n",
    "    plt.title('Distribution of ' + col)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_plot(df=df, col='item_price', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_plot(df=df, col='sale_amount', bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Date Parts\n",
    "\n",
    "4. Add a 'month' and 'day of week' column to your dataframe, derived from the index using the keywords for those date parts.\n",
    "\n",
    "\n",
    ">**If you have upgraded your pandas, use `.day_name()`, if not, `.weekday_name`. To check your pandas version, `pd.__version__`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df.index.month\n",
    "df['weekday'] = df.index.day_name()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create New Calculated Column Using .assign()\n",
    "\n",
    "```python\n",
    "df = df.assign(new_col_name = your calculation)\n",
    "```\n",
    "\n",
    "5. Add a column to your dataframe, `sales_total`, which is a derived from `sale_amount` (total items) and `item_price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(sales_total = df.sale_amount * df.item_price)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Using .diff()\n",
    "\n",
    "6. Using `df.diff()` function, create a new column that is the result of the current sales - the previous days sales.\n",
    "\n",
    "    {default}\n",
    "\n",
    "```python\n",
    "df.diff(periods=1, axis=0)\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df grouped by total sales by day and create a column with the daily difference\n",
    "\n",
    "sales_df = df.resample('D')[['sales_total']].sum()\n",
    "sales_df = sales_df.assign(sales_diff = df.resample('D')[['sales_total']].sum().diff())\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Build Functions\n",
    "\n",
    "**Why use the category type instead of the object type? This is a personal preference here because I wanted the functionality of the category object for future use. If you're interested, I thought [this article](https://pbpython.com/pandas_dtypes_cat.html) did a great job at speaking to the topic.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to take care of changing some data types here\n",
    "\n",
    "df = (df.astype({'sale_id': object, \n",
    "                 'store_id': object, \n",
    "                 'store_zipcode': object, \n",
    "                 'item_id': object, \n",
    "                 'item_upc12': object, \n",
    "                 'item_upc14': object, \n",
    "                 'month': 'category', \n",
    "                 'weekday': 'category'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_hists(df, bins=20):\n",
    "    \"\"\"\n",
    "    Function to take in a DataFrame, bins default 20,\n",
    "    select only numeric dtypes, and\n",
    "    display histograms for each numeric column\n",
    "    \"\"\"\n",
    "    num_df = df.select_dtypes(include=np.number)\n",
    "    num_df.hist(bins=bins, color='thistle')\n",
    "    plt.suptitle('Numeric Column Distributions')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_hists(df, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepped_store_df():\n",
    "    \"\"\"\n",
    "    Function to acquire and prepare\n",
    "    store dataframe and show\n",
    "    distributions for numeric columns\n",
    "    \"\"\"\n",
    "    # Acquire the df\n",
    "    df = get_store_data()\n",
    "    \n",
    "    # Create date part columns\n",
    "    df['month'] = df.index.month\n",
    "    df['weekday'] = df.index.day_name()\n",
    "    \n",
    "    # Create calculated columns\n",
    "    df = df.assign(sales_total = df.sale_amount * df.item_price)\n",
    "    df = df.assign(sales_diff = df.sales_total.diff(periods=1))\n",
    "    \n",
    "    # Change dtypes of numeric columns to object and category\n",
    "    df = (df.astype({'sale_id': object, \n",
    "                     'store_id': object, \n",
    "                     'store_zipcode': object, \n",
    "                     'item_id': object, \n",
    "                     'item_upc12': object, \n",
    "                     'item_upc14': object, \n",
    "                     'month': 'category', \n",
    "                     'weekday': 'category'}))\n",
    "    \n",
    "    # Display distributions of numeric columns\n",
    "    numeric_hists(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepped_store_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acuire OPS German Energy df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = german_energy_csv()\n",
    "gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4 Prepare German Energy df\n",
    "\n",
    "1. Convert date column to datetime format. <font color=red>(I already did this in acquire.)</font>\n",
    "\n",
    "\n",
    "2. Plot the distribution of each of your variables. <font color=red>(Use function from above.)</font>\n",
    "\n",
    "```python\n",
    "numeric_hists(gdf)\n",
    "```\n",
    "\n",
    "3. Set the index to be the datetime variable. <font color=red>(I already did this in acquire.)</font>\n",
    "\n",
    "```python\n",
    "url = 'https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv'```\n",
    "```python\n",
    "df = pd.read_csv(url, parse_dates=True, index_col='Date')\n",
    "```\n",
    "\n",
    "\n",
    "4. Add a month and a year column to your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['month'] = gdf.index.month.astype('category')\n",
    "gdf['year'] = gdf.index.year.astype('category')\n",
    "gdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Build Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepped_energy():\n",
    "    \"\"\"\n",
    "    Function the acquires and returns \n",
    "    a prepared df for the OPS German Energy data\n",
    "    and displays historgrams for numeric columns\n",
    "    \"\"\"\n",
    "    # Acquire Datetime df\n",
    "    gdf = german_energy_csv()\n",
    "    \n",
    "    # Create new date part columns as category dtypes\n",
    "    gdf['month'] = gdf.index.month.astype('category')\n",
    "    gdf['year'] = gdf.index.year.astype('category')\n",
    "    \n",
    "    # Plot numeric column distributions\n",
    "    numeric_hists(gdf)\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = prepped_energy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire San Francisco Temps DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "sfdf = data.sf_temps()\n",
    "sfdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sfdf to a DateTime Series df\n",
    "\n",
    "sfdf['date'] = pd.to_datetime(sfdf.date)\n",
    "sfdf = sfdf.set_index('date').sort_index()\n",
    "sfdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_hists(sfdf, bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resample by the day and take the average temperature. Visualize the average temperature over time.\n",
    "\n",
    ">One awesome feature of DateTime Index is simplicity in plotting, as matplotlib will automatically treat it as x axis, so we don’t need to explicitly specify anything.\n",
    "\n",
    "```python\n",
    "datetime_index_df.col.plot(kind='bar', color='thistle)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample by D and get average daily temp, (shift + option + 8 == degree symbol)\n",
    "\n",
    "sfdf.resample('D').mean().plot(color='peru')\n",
    "\n",
    "plt.title('San Francisco 2010 Average Daily Temperatures')\n",
    "plt.ylabel('Temp in °F')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write the code necessary to visualize the minimum temperature over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample by D and get minimum daily temp, (shift + option + 8 == degree symbol)\n",
    "\n",
    "sfdf.resample('D').min().plot(color='lightskyblue')\n",
    "\n",
    "plt.title('San Francisco 2010 Minimum Daily Temperatures')\n",
    "plt.ylabel('Temp in °F')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write the code necessary to visualize the maximum temperature over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample by D and get maximum daily temp, (shift + option + 8 == degree symbol)\n",
    "\n",
    "sfdf.resample('D').max().plot(color='crimson')\n",
    "\n",
    "plt.title('San Francisco 2010 Maximum Daily Temperatures')\n",
    "plt.ylabel('Temp in °F')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Which month is the coldest, on average?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I wanted to see the coldest month and the temp, so I used .loc to pull up observation by index\n",
    "\n",
    "sfdf.loc[sfdf.resample('M').mean().idxmin()]\n",
    "#sfdf.resample('M').mean().idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Which month has the highest average temperature?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I wanted to see the hotest month and the temp, so I used .loc to pull up observation by index\n",
    "\n",
    "sfdf.loc[sfdf.resample('M').mean().idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Resample by the day and calculate the min and max temp for the day. Use this resampled dataframe to calculate the change in temperature for the day. Which month has the highest daily temperature variability?\n",
    "\n",
    "- Hint: `.agg(['min', 'max'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample by day and get min and max temps in df\n",
    "min_max = sfdf.resample('D').agg(['min', 'max'])\n",
    "min_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take care of multi-index of df\n",
    "\n",
    "min_max.columns = ['min_temp', 'max_temp']\n",
    "min_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp_range column\n",
    "\n",
    "min_max['temp_range'] = min_max.max_temp - min_max.min_temp\n",
    "min_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return min, max, and max temp_range for month with highest range\n",
    "\n",
    "min_max.loc[min_max.temp_range.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Bonus: Visualize the daily min, average, and max temperature over time on a single line plot.\n",
    "\n",
    "- i.e. the min, average, and maximum temperature should be 3 seperate lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agg df\n",
    "\n",
    "temp_agg = sfdf.resample('D').agg(['min', 'mean', 'max'])\n",
    "temp_agg.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle multi-index\n",
    "\n",
    "temp_agg.columns = ['min_temp', 'mean_temp', 'max_temp']\n",
    "temp_agg.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_agg.plot(color=['lightskyblue', 'peru', 'crimson'])\n",
    "\n",
    "plt.legend()\n",
    "plt.title('San Francisco 2010 Daily Temperature Breakdown')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Temperature in °F')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire flights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = data.flights_20k()\n",
    "fdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert df to DateTime Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sfdf to a DateTime Series df\n",
    "\n",
    "fdf = fdf.set_index('date').sort_index()\n",
    "fdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First datetime in dataset is January 1 at 1 AM\n",
    "\n",
    "fdf.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last datetime in dataset is March 31 at 9:30\n",
    "\n",
    "fdf.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is some skewed data!\n",
    "\n",
    "numeric_hists(fdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convert any negative delays to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use original for quick visual check .where() is working.\n",
    "\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # df.col = np.where(this_is_true, do_this, else_do_that)\n",
    "\n",
    "fdf.delay = np.where(fdf.delay < 0, 0, fdf.delay)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I validate that I have replaced negative numbers in delay\n",
    "\n",
    "fdf[fdf.delay < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Which hour of the day has the highest average delay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to create a column for hour, so I can groupby hour\n",
    "\n",
    "fdf['hour'] = fdf.index.hour.astype('category')\n",
    "fdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I groupby hour and find the mean value for delay for each hour\n",
    "# I sort the values to find that 3 PM has the highest value for average delay\n",
    "\n",
    "fdf.groupby('hour')[['delay']].mean().sort_values(by='delay', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Does the day of the week make a difference in the delay amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for the day of the week, so I can groupby weekday\n",
    "\n",
    "fdf['weekday'] = fdf.index.day_name()\n",
    "fdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I groupby the weekday and examine the average delay\n",
    "\n",
    "fdf.groupby('weekday')[['delay']].mean().sort_values('delay', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "cats.reverse()\n",
    "\n",
    "fdf.groupby('weekday')[['delay']].mean().reindex(cats).plot(kind='barh', color='thistle')\n",
    "plt.title('Average Delay by Day of the Week')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Delay in Minutes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting. I wanted to see the weekday/hour combo with the highest avg delay\n",
    "# Friday at 3 PM tops the charts; people are flying home and away from home.\n",
    "\n",
    "fdf.groupby(['weekday', 'hour'])[['delay']].mean().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Does the month make a difference in the delay amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a month column to groupby month. This dataset contains Jan, Feb, March\n",
    "\n",
    "fdf['month'] = fdf.index.month.astype('category')\n",
    "fdf.month.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I groupby month to examine the average delay by month\n",
    "# It looks like February, typically the coldest month of the year in the N. Hemisphere,\n",
    "# has slightly more delay time on average than January\n",
    "\n",
    "fdf.groupby('month')[['delay']].mean().sort_values(by='delay', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just Curious Stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# February at 3 PM had the highest average delay\n",
    "\n",
    "fdf.groupby(['month', 'hour'])[['delay']].mean().sort_values(by='delay', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.delay.plot(color='thistle')\n",
    "\n",
    "plt.title('There Are Our Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf[fdf.month == 2].sort_values(by='delay', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is our longest delay. The 0 value for delay makes the delay average for this month, day, time combo drop substantially. \n",
    "\n",
    "fdf.loc[fdf.delay.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "cats.reverse()\n",
    "\n",
    "fdf.weekday.value_counts().reindex(cats).plot(kind='barh', color='thistle')\n",
    "\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Number of Flights')\n",
    "plt.xticks(rotation=0)\n",
    "plt.title('Distribution of Flights by Weekday in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.weekday.value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was curious about store sales by location\n",
    "\n",
    "df.groupby('store_address').sales_total.sum().plot(kind='barh', color='thistle')\n",
    "\n",
    "plt.title('Total Sales by Store Address')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('US Dollars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What were stores selling the most of?\n",
    "\n",
    "df.groupby('store_address')[['sale_amount']].max().sort_values(by='sale_amount', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What were stores selling the least of?\n",
    "\n",
    "df.groupby('store_address')[['sale_amount']].min().sort_values(by='sale_amount', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
